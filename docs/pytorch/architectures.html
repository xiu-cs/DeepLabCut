
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>DeepLabCut 3.0 - PyTorch Model Architectures &#8212; DeepLabCut</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/pytorch/architectures';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="QUICK GUIDE to single Animal Training:" href="../quick-start/single_animal_quick_guide.html" />
    <link rel="prev" title="The PyTorch Configuration file" href="pytorch_config.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="DeepLabCut - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="DeepLabCut - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    Welcome! 👋
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../UseOverviewGuide.html">🥳 Get started with DeepLabCut: our key recommendations</a></li>


<li class="toctree-l1"><a class="reference internal" href="../course.html">DeepLabCut Self-paced Course</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">How To Install DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/installTips.html">Installation Tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">DeepLabCut Docker containers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Main User Guides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../standardDeepLabCut_UserGuide.html">DeepLabCut User Guide (for single animal projects)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../maDLC_UserGuide.html">DeepLabCut for Multi-Animal Projects</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Overviewof3D.html">3D DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../HelperFunctions.html">Helper &amp; Advanced Optional Function Documentation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Graphical User Interfaces (GUIs)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../gui/PROJECT_GUI.html">Interactive Project Manager GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gui/napari_GUI.html">napari labeling GUI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DLC3 PyTorch Specific Docs</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="user_guide.html">DeepLabCut 3.0 - PyTorch User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_config.html">The PyTorch Configuration file</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">DeepLabCut 3.0 - PyTorch Model Architectures</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Quick Start Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../quick-start/single_animal_quick_guide.html">QUICK GUIDE to single Animal Training:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick-start/tutorial_maDLC.html">Multi-animal pose estimation with DeepLabCut: A 5-minute tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🚀 Beginner's Guide to DeepLabCut</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../beginner-guides/beginners-guide.html">Using DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner-guides/manage-project.html">Setting up what keypoints to track</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner-guides/labeling.html">Labeling GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner-guides/Training-Evaluation.html">Neural Network training and evaluation in the GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner-guides/video-analysis.html">Video Analysis with DeepLabCut</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hardware Tips</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../recipes/TechHardware.html">Technical (Hardware) Considerations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepLabCut-Live!</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../deeplabcutlive.html">DeepLabCut-Live!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🦄 DeepLabCut Model Zoo</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ModelZoo.html">The DeepLabCut Model Zoo!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/UsingModelZooPupil.html">Using ModelZoo models on your own datasets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">🧑‍🍳 Cookbook (detailed helper guides)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../convert_maDLC.html">How to convert a pre-2.2 project for use with DeepLabCut 2.2 or later</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/OtherData.html">How to use data labeled outside of DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/io.html">Input/output manipulations with DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/nn.html">Model training tips &amp; tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/post.html">Some data processing recipes!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/BatchProcessing.html">Automate training and video analysis: Batch Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/DLCMethods.html">How to write a DLC Methods Section</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/ClusteringNapari.html">Clustering in the napari-DeepLabCut GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/OpenVINO.html">Intel OpenVINO backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/flip_and_rotate.html">Improving network performance on unbalanced data via augmentation 🦇</a></li>


<li class="toctree-l1"><a class="reference internal" href="../recipes/pose_cfg_file_breakdown.html">The <code class="docutils literal notranslate"><span class="pre">pose_cfg.yaml</span></code> Guideline Handbook</a></li>



<li class="toctree-l1"><a class="reference internal" href="../recipes/publishing_notebooks_into_the_DLC_main_cookbook.html">Publishing Notebooks into the Main DLC Cookbook</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepLabCut Benchmarking</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../benchmark.html">DeepLabCut benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="Benchmarking_shuffle_guide.html">DeepLabCut Benchmarking - User Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mission &amp; Contribute</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../MISSION_AND_VALUES.html">Mission and Values of DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roadmap.html">A development roadmap for DeepLabCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Governance.html">Governance Model of DeepLabCut</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Citations for DeepLabCut</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../citation.html">How to Cite DeepLabCut</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/DeepLabCut/DeepLabCut" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DeepLabCut/DeepLabCut/issues/new?title=Issue%20on%20page%20%2Fdocs/pytorch/architectures.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/docs/pytorch/architectures.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>DeepLabCut 3.0 - PyTorch Model Architectures</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-networks-architectures">Neural Networks Architectures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#information-on-single-animal-models">Information on Single Animal Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approaches-to-multi-animal-pose-estimation">Approaches to Multi-Animal pose estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bottom-up-estimation">Bottom-up estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#backbones-with-part-affinity-fields">Backbones with Part-Affinity Fields</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#top-down-estimation">Top-down estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hybrid-bottom-up-bu-plus-a-conditioned-top-down-ctd">Hybrid, Bottom-up (BU) plus a ``conditioned” Top-down (CTD)</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="deeplabcut-3-0-pytorch-model-architectures">
<span id="dlc3-architectures"></span><h1>DeepLabCut 3.0 - PyTorch Model Architectures<a class="headerlink" href="#deeplabcut-3-0-pytorch-model-architectures" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>You can see a list of supported architectures/variants by using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">deeplabcut.pose_estimation_pytorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">available_models</span>
<span class="nb">print</span><span class="p">(</span><span class="n">available_models</span><span class="p">())</span>
</pre></div>
</div>
<p>You can see a list of supported object detection architectures/variants by using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">deeplabcut.pose_estimation_pytorch</span><span class="w"> </span><span class="kn">import</span> <span class="n">available_detectors</span>
<span class="nb">print</span><span class="p">(</span><span class="n">available_detectors</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="neural-networks-architectures">
<h2>Neural Networks Architectures<a class="headerlink" href="#neural-networks-architectures" title="Link to this heading">#</a></h2>
<p>Several architectures are currently implemented in DeepLabCut PyTorch (more will come,
and you can add more easily in our new model registry). Also check out the explanations of bottom-up/top-down below.</p>
<p><strong>ResNets</strong></p>
<ul class="simple">
<li><p>Adapted from <a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html">He, Kaiming, et al. “Deep residual learning for image recognition.” Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2016.</a> and [Insafutdinov, Eldar et al. “DeeperCut: A Deeper, Stronger, and Faster Multi-Person Pose Estimation Model”. European Conference on Computer Vision (ECCV) 2016.]</p></li>
<li><p>Current bottom-up variants are <code class="docutils literal notranslate"><span class="pre">resnet_50</span></code>, <code class="docutils literal notranslate"><span class="pre">resnet_101</span></code></p></li>
<li><p>Current top-down variants are <code class="docutils literal notranslate"><span class="pre">top_down_resnet_101</span></code>, <code class="docutils literal notranslate"><span class="pre">top_down_resnet_50</span></code></p></li>
</ul>
<p><strong>HRNet</strong></p>
<ul class="simple">
<li><p>Adapted from <a class="reference external" href="https://arxiv.org/abs/1908.07919">Wang, Jingdong, et al. “Deep high-resolution representation learning for visual recognition.” IEEE transactions on pattern analysis and machine intelligence 43.10 (2020): 3349-3364.</a></p></li>
<li><p>Current variants are <code class="docutils literal notranslate"><span class="pre">hrnet_w18</span></code>, <code class="docutils literal notranslate"><span class="pre">hrnet_w32</span></code>, <code class="docutils literal notranslate"><span class="pre">hrnet_w48</span></code>,</p></li>
<li><p>Current top-down variants are <code class="docutils literal notranslate"><span class="pre">top_down_hrnet_w18</span></code>, <code class="docutils literal notranslate"><span class="pre">top_down_hrnet_w32</span></code>, <code class="docutils literal notranslate"><span class="pre">top_down_hrnet_w48</span></code></p></li>
<li><p>Slower but typically more powerful than ResNets</p></li>
</ul>
<p><strong>DEKR</strong></p>
<ul class="simple">
<li><p>Adapted from <a class="reference external" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Geng_Bottom-Up_Human_Pose_Estimation_via_Disentangled_Keypoint_Regression_CVPR_2021_paper.pdf">Geng, Zigang et al. “Bottom-Up Human Pose Estimation Via Disentangled Keypoint Regression.” Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2021.</a></p></li>
<li><p>This model is a bottom-up model using HRNet as a backbone. It learns to predict the center of each animal, and predicts the offset between each animal center and their keypoints</p></li>
<li><p>Current variants that are implemented (from smallest to largest): <code class="docutils literal notranslate"><span class="pre">dekr_w18</span></code>, <code class="docutils literal notranslate"><span class="pre">dekr_w32</span></code>, <code class="docutils literal notranslate"><span class="pre">dekr_w48</span></code></p></li>
<li><p>Note, this is a powerful multi-animal model but very heavy (slow)</p></li>
</ul>
<p><strong>BUCTD</strong></p>
<ul class="simple">
<li><p>Adapted from <a class="reference external" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.pdf">Zhou*, Stoffl*, Mathis, Mathis. “Rethinking Pose Estimation in Crowds: Overcoming the Detection Information Bottleneck and Ambiguity.” Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). 2023</a></p></li>
<li><p><a class="reference external" href="https://paperswithcode.com/sota/pose-estimation-on-crowdpose?p=rethinking-pose-estimation-in-crowds"><img alt="PWC" src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/rethinking-pose-estimation-in-crowds/pose-estimation-on-crowdpose" /></a></p></li>
<li><p>This is a top-performing multi-animal method that combines the strengths of bottom-up and top-down approaches, and delivers exceptional performance on humans too (which are also animals)</p></li>
<li><p>It can be used with a diverse set of architectures. Current variants are: <code class="docutils literal notranslate"><span class="pre">ctd_coam_w32</span></code>, <code class="docutils literal notranslate"><span class="pre">ctd_coam_w48</span></code>/<code class="docutils literal notranslate"><span class="pre">ctd_coam_w48_human</span></code>, <code class="docutils literal notranslate"><span class="pre">ctd_prenet_hrnet_w32</span></code>, <code class="docutils literal notranslate"><span class="pre">ctd_prenet_hrnet_w48</span></code>, <code class="docutils literal notranslate"><span class="pre">ctd_prenet_rtmpose_s</span></code>, <code class="docutils literal notranslate"><span class="pre">ctd_prenet_rtmpose_m</span></code>, <code class="docutils literal notranslate"><span class="pre">ctd_prenet_rtmpose_x</span></code>/<code class="docutils literal notranslate"><span class="pre">ctd_prenet_rtmpose_x_human</span></code></p></li>
</ul>
<p><strong>DLCRNet</strong></p>
<ul class="simple">
<li><p>From <a class="reference external" href="https://www.nature.com/articles/s41592-022-01443-0">Lauer, Zhou, et al. “Multi-animal pose estimation, identification and tracking with DeepLabCut.” Nature Methods 19.4 (2022): 496-504.</a></p></li>
<li><p>This model uses a multi-scale variant of a ResNet as a backbone, and part-affinity fields to assemble individuals</p></li>
<li><p>Variants: <code class="docutils literal notranslate"><span class="pre">dlcrnet_stride16_ms5</span></code>, <code class="docutils literal notranslate"><span class="pre">dlcrnet_stride32_ms5</span></code></p></li>
</ul>
<p><strong>RTMPose</strong></p>
<ul class="simple">
<li><p>From <a class="reference external" href="https://arxiv.org/abs/2303.07399">Jiang, Tao et al. “RTMPose: Real-Time Multi-Person Pose Estimation based on MMPose”</a></p></li>
<li><p>Top-down pose estimation model using a fast CSPNeXt backbone with a SimCC-style head</p></li>
<li><p>Variants: <code class="docutils literal notranslate"><span class="pre">rtmpose_s</span></code>, <code class="docutils literal notranslate"><span class="pre">rtmpose_m</span></code>, <code class="docutils literal notranslate"><span class="pre">rtmpose_x</span></code></p></li>
</ul>
<p><strong>AnimalTokenPose</strong></p>
<ul class="simple">
<li><p>Adapted from <a class="reference external" href="https://arxiv.org/abs/2104.03516">Li, Yanjie, et al. “Tokenpose: Learning keypoint tokens for human pose estimation.” Proceedings of the IEEE/CVF International conference on computer vision. 2021.</a> as in Ye et al. “SuperAnimal pretrained pose estimation models for behavioral analysis.” Nature Communications. 2024](<a class="reference external" href="https://arxiv.org/abs/2203.07436">https://arxiv.org/abs/2203.07436</a>)</p></li>
<li><p>One variant is implemented as: <code class="docutils literal notranslate"><span class="pre">animal_tokenpose_base</span></code> for video inference only (we don’t support directly training this within deeplabcut)</p></li>
</ul>
</section>
<section id="information-on-single-animal-models">
<h2>Information on Single Animal Models<a class="headerlink" href="#information-on-single-animal-models" title="Link to this heading">#</a></h2>
<p>Single-animal models are composed of a backbone (encoder) and a head (decoder)
predicting the position of keypoints. The default head contains a single deconvolutional
layer. To create the single animal model composed of a backbone and head, you can call
<code class="docutils literal notranslate"><span class="pre">deeplabcut.create_training_dataset</span></code> with <code class="docutils literal notranslate"><span class="pre">net_type</span></code> set to the backbone name (e.g.
<code class="docutils literal notranslate"><span class="pre">resnet_50</span></code> or <code class="docutils literal notranslate"><span class="pre">hrnet_w32</span></code>).</p>
<p>If you want to add a second deconvolutional layer (which will make your model slower,
but it might improve performance), you can simply edit your <code class="docutils literal notranslate"><span class="pre">pytorch_config.yaml</span></code> file.</p>
<p>Of course, any multi-animal model can also be used for single-animal projects!</p>
</section>
<section id="approaches-to-multi-animal-pose-estimation">
<h2>Approaches to Multi-Animal pose estimation<a class="headerlink" href="#approaches-to-multi-animal-pose-estimation" title="Link to this heading">#</a></h2>
<p>Single-animal pose estimation is quite straightforward: the model takes an image as
input, and it outputs the predicted coordinate of each bodypart.</p>
<p>Multi-animal pose estimation is more complex. Not only do you need to localize bodyparts
in the image, but you also need to group bodyparts per individual. There are two main
approaches to multi-animal pose estimation.</p>
<section id="bottom-up-estimation">
<h3>Bottom-up estimation<a class="headerlink" href="#bottom-up-estimation" title="Link to this heading">#</a></h3>
<p>The first approach, <strong>bottom-up</strong> pose estimation, starts by detecting bodyparts in the
image before figuring out how they belong together (i.e., which keypoints belong to the
same animal).</p>
<p><img alt="Schema representing the bottom-up approach to pose estimation" src="../../_images/bottom-up-approach.png" /></p>
<section id="backbones-with-part-affinity-fields">
<h4>Backbones with Part-Affinity Fields<a class="headerlink" href="#backbones-with-part-affinity-fields" title="Link to this heading">#</a></h4>
<p>As in DeepLabCut 2.X, the base multi-animal model is composed of a backbone (encoder)
and a head predicting keypoints and part-affinity fields (PAFs). These PAFs are used to
assemble keypoints for individuals.</p>
<p>Passing a backbone as a net type (e.g., <code class="docutils literal notranslate"><span class="pre">resnet_50</span></code>, <code class="docutils literal notranslate"><span class="pre">hrnet_w32</span></code>) for a multi-animal
project will create a model consisting of a backbone and a heatmap + PAF head.</p>
</section>
</section>
<section id="top-down-estimation">
<h3>Top-down estimation<a class="headerlink" href="#top-down-estimation" title="Link to this heading">#</a></h3>
<p>The second approach, <strong>top-down</strong> pose estimation, uses a two-step approach. A first
model (an object detector) is used to localize every animal present in the image through
its bounding box. Then, the pose for each animal is determined by predicting bodyparts
in each bounding box. The pose estimation</p>
<p><img alt="Schema representing the top-down approach to pose estimation" src="../../_images/top-down-approach.png" /></p>
<p>The top-down approach tends to be more accurate in less crowded scenes, as the pose
model only needs to process the pixels related to a single animal. However, in more
crowded scenes, the pose estimation task becomes ambiguous. Multiple overlapping
individuals will have very similar bounding boxes, and the pose model has no way of
knowing which animal it is supposed to predict keypoints for.</p>
<p>The bottom-up approach does not have this ambiguïty, and also has the advantage of
only needing to run a pose estimation model, instead of needing to run an object
detector first. However, grouping keypoints is a difficult problem.</p>
<p>Hence any single-animal model can be transformed into a top-down, multi-animal model. To
do so, simply prefix <code class="docutils literal notranslate"><span class="pre">top_down</span></code> to your single-animal model name. Currently, the
following detectors are available: <code class="docutils literal notranslate"><span class="pre">ssdlite</span></code>, <code class="docutils literal notranslate"><span class="pre">fasterrcnn_mobilenet_v3_large_fpn</span></code>,
<code class="docutils literal notranslate"><span class="pre">fasterrcnn_resnet50_fpn_v2</span></code>.</p>
</section>
<section id="hybrid-bottom-up-bu-plus-a-conditioned-top-down-ctd">
<h3>Hybrid, Bottom-up (BU) plus a ``conditioned” Top-down (CTD)<a class="headerlink" href="#hybrid-bottom-up-bu-plus-a-conditioned-top-down-ctd" title="Link to this heading">#</a></h3>
<p>A new approach to pose estimation, named bottom-up conditioned top-down (or <strong>BUCTD</strong>), was
introduced in <a class="reference external" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.pdf">Zhou, Stoffl, Mathis, Mathis. “Rethinking Pose Estimation in Crowds:
Overcoming the Detection Information Bottleneck and Ambiguity.” Proceedings of the
IEEE/CVF International Conference on Computer Vision (ICCV). 2023</a>
. It’s a hybrid two-stage approach leveraging the strengths of the bottom-up and
top-down approaches to overcome the ambiguïty introduced through bounding boxes. Instead
of using an object detection model to localize individuals, it uses a bottom-up pose
estimation model. The predictions made by the bottom-up model are given as proposals (or
<em>conditions</em>) to the pose estimation model. This is illustrated in the figure below. In modern language, one could state that CTD models are “pose-promptable”.</p>
<p><img alt="BUCTD" src="https://github.com/amathislab/BUCTD/raw/main/media/BUCTD_fig1.png" />
Zhou, Mu, et al. <em>“Rethinking pose estimation in crowds: overcoming the
detection information bottleneck and ambiguity.”</em> Proceedings of the IEEE/CVF
International Conference on Computer Vision. 2023.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/pytorch"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pytorch_config.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">The PyTorch Configuration file</p>
      </div>
    </a>
    <a class="right-next"
       href="../quick-start/single_animal_quick_guide.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">QUICK GUIDE to single Animal Training:</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-networks-architectures">Neural Networks Architectures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#information-on-single-animal-models">Information on Single Animal Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approaches-to-multi-animal-pose-estimation">Approaches to Multi-Animal pose estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bottom-up-estimation">Bottom-up estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#backbones-with-part-affinity-fields">Backbones with Part-Affinity Fields</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#top-down-estimation">Top-down estimation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hybrid-bottom-up-bu-plus-a-conditioned-top-down-ctd">Hybrid, Bottom-up (BU) plus a ``conditioned” Top-down (CTD)</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The DeepLabCut Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>Powered by <a href="https://jupyterbook.org/">Jupyter Book</a>.</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>